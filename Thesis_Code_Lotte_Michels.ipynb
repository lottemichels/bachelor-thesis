{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bachelor Thesis Code - Lotte Michels - 2055481\n"
      ],
      "metadata": {
        "id": "U9urI_FW6XQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install/Import relevant modules\n",
        "\n",
        "#!pip install mne # Uncomment this to install MNE-Python\n",
        "import mne\n",
        "from mne.preprocessing import ICA\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "sZ_IHfrAbZFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "F1AJ2zr119XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrieve all the datafiles\n",
        "\n",
        "datafiles = os.listdir('drive/MyDrive/Bachelorthesis/Raw Data') #\n",
        "datafiles.sort()\n",
        "print(\"There are {} files in total\".format(len(datafiles)))\n",
        "print(datafiles)"
      ],
      "metadata": {
        "id": "U4Y1_iTkiAfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code block will convert all datafiles to _raw.fif files\n",
        "\n",
        "for p_number in range(1, 18): # The files for the first round of data collection (participants 1-17) are in a different format than the second round\n",
        "  p_code = str(p_number)\n",
        "  if p_number < 10:\n",
        "    p_code = \"0{}\".format(p_code)\n",
        "\n",
        "  LT_files = []\n",
        "  for filename in datafiles:\n",
        "    if p_code in filename and 'LT' in filename:\n",
        "      raw = mne.io.read_raw_bdf(\"../Raw Data/{}\".format(filename))\n",
        "      LT_files.append(raw)\n",
        "  if LT_files == []:\n",
        "    print(\"No LT files found for EPM{}\".format(p_code))\n",
        "  else:\n",
        "    LT = mne.concatenate_raws(LT_files)\n",
        "    LT.save('drive/MyDrive/Bachelorthesis/Concatenated Files/EPM{}_LT_raw.fif'.format(p_code), overwrite=True)\n",
        "\n",
        "  MT_files = []\n",
        "  for filename in datafiles:\n",
        "    if p_code in filename and 'MT' in filename:\n",
        "      raw = mne.io.read_raw_bdf(\"../Raw Data/{}\".format(filename))\n",
        "      MT_files.append(raw)\n",
        "  if MT_files == []:\n",
        "    print(\"No MT files found for EPM{}\".format(p_code))\n",
        "  else:\n",
        "    MT = mne.concatenate_raws(MT_files)\n",
        "    MT.save('drive/MyDrive/Bachelorthesis/Concatenated Files/EPM{}_MT_raw.fif'.format(p_code), overwrite=True)\n",
        "\n",
        "  DT_files = []\n",
        "  for filename in datafiles:\n",
        "    if p_code in filename and 'DT' in filename:\n",
        "      raw = mne.io.read_raw_bdf(\"../Raw Data/{}\".format(filename))\n",
        "      DT_files.append(raw)\n",
        "  if DT_files == []:\n",
        "    print(\"No DT files found for EPM{}\".format(p_code))\n",
        "  else:\n",
        "    DT = mne.concatenate_raws(DT_files)\n",
        "    DT.save('drive/MyDrive/Bachelorthesis/Concatenated Files/EPM{}_DT_raw.fif'.format(p_code), overwrite=True)\n",
        "\n",
        "  print(\"Completed EPM{}\".format(p_code))\n",
        "  print(\"\")\n",
        "\n",
        "for p_number in range(21, 33): # The files for the second round of data collection (participants 21-32) are in a different format than the first round\n",
        "  p_code = str(p_number)\n",
        "\n",
        "  LT_file = \"EPM{}_LT.bdf\".format(p_code)\n",
        "  LT = mne.io.read_raw_bdf(\"../Second Round/{}\".format(LT_file))\n",
        "  LT.save('drive/MyDrive/Bachelorthesis/Concatenated Files/EPM{}_LT_raw.fif'.format(p_code), overwrite=True)\n",
        "\n",
        "  if p_code == \"24\": #there are two MT files for p24 (technical issues during the experiment)\n",
        "    MT_files = []\n",
        "    f1 = mne.io.read_raw_bdf(\"../Second Round/EPM24_MT1.bdf\")\n",
        "    MT_files.append(f1)\n",
        "    f2 = mne.io.read_raw_bdf(\"../Second Round/EPM24_MT2.bdf\")\n",
        "    MT_files.append(f2)\n",
        "    MT = mne.concatenate_raws(MT_files)\n",
        "    MT.save('drive/MyDrive/Bachelorthesis/Concatenated Files/EPM24_MT_raw.fif', overwrite=True)\n",
        "  else:\n",
        "    MT_file = \"EPM{}_MT.bdf\".format(p_code)\n",
        "    MT = mne.io.read_raw_bdf(\"../Second Round/{}\".format(MT_file))\n",
        "    MT.save('drive/MyDrive/Bachelorthesis/Concatenated Files/EPM{}_MT_raw.fif'.format(p_code), overwrite=True)\n",
        "\n",
        "  if p_code == \"25\": #there are two DT files for p25 (technical issues during the experiment)\n",
        "    DT_files = []\n",
        "    f1 = mne.io.read_raw_bdf(\"../Second Round/EPM25_DT1.bdf\")\n",
        "    DT_files.append(f1)\n",
        "    f2 = mne.io.read_raw_bdf(\"../Second Round/EPM25_DT2.bdf\")\n",
        "    DT_files.append(f2)\n",
        "    DT = mne.concatenate_raws(DT_files)\n",
        "    DT.save('drive/MyDrive/Bachelorthesis/Concatenated Files/EPM25_DT_raw.fif', overwrite=True)\n",
        "  else:\n",
        "    DT_file = \"EPM{}_DT.bdf\".format(p_code)\n",
        "    DT = mne.io.read_raw_bdf(\"../Second Round/{}\".format(DT_file))\n",
        "    DT.save('drive/MyDrive/Bachelorthesis/Concatenated Files/EPM{}_DT_raw.fif'.format(p_code), overwrite=True)\n",
        "\n",
        "  print(\"Completed EPM{}\".format(p_code))\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "RJtbx5ikzGA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code block will filter the data, run ICA and plot the ICA results for each file\n",
        "\n",
        "for f in os.listdir(\"drive/MyDrive/Bachelorthesis/Concatenated Files\"):\n",
        "  filename = str(f)\n",
        "  subject = filename.strip(\"EPM\")\n",
        "  subject = subject[0:2]\n",
        "  if subject[0] == \"0\":\n",
        "    subject = subject.strip(\"0\")\n",
        "  subject = int(subject)\n",
        "\n",
        "  raw = mne.io.read_raw_fif(\"drive/MyDrive/Bachelorthesis/Concatenated Files/{}\".format(filename), preload=True) #Or use testfile.load_data() for loading\n",
        "  # To print file info use print(testfile.info)\n",
        "  # To print the channels use print(testfile.ch_names)\n",
        "\n",
        "  # Set reference\n",
        "  raw.set_eeg_reference(ref_channels=['Cz'])\n",
        "\n",
        "  # Adjust channel types\n",
        "  if subject < 21: # the data collected for participants from the first round (1-17) were collected with a different system than in the second round\n",
        "    raw.set_channel_types(mapping={'EXG1':'eog', 'EXG2':'eog', 'EXG3':'eog', 'EXG4':'eog', 'EXG5':'eog', 'EXG6':'eog', 'EXG7':'misc', 'EXG8':'misc', 'GSR1':'misc', 'GSR2':'misc', 'Erg1':'misc', 'Erg2':'misc', 'Resp':'misc', 'Plet':'misc', 'Temp':'misc', 'Status':'stim'})\n",
        "    # Rereference to the mastoid links\n",
        "    raw.set_eeg_reference(ref_channels=['EXG1', 'EXG2'])\n",
        "  else: # the data collected for participants from the second round (21-32) were collected with a different system than in the first round\n",
        "    raw.set_channel_types(mapping={'M1':'eog', 'M2':'eog', 'Up':'eog', 'Down':'eog', 'Left':'eog', 'Right':'eog', 'Status':'stim'}) \n",
        "    # Rereference to the mastoid links\n",
        "    raw.set_eeg_reference(ref_channels=['M1', 'M2'])\n",
        "\n",
        "  # Apply signal filtering (while maintaining the raw file)\n",
        "  filt_raw = raw.copy()\n",
        "  filt_raw.notch_filter(freqs=50) #to remove power artefacts from the measuring devices, which are known to be at 50 Hz\n",
        "  filt_raw.filter(l_freq=0.1, h_freq=None)\n",
        "  filt_raw.filter(l_freq=None, h_freq=100)\n",
        "\n",
        "  # Align sensors with their correct position (EEG Sensor Cap)\n",
        "  biosemi_montage = mne.channels.make_standard_montage('biosemi64')\n",
        "  filt_raw.set_montage(biosemi_montage)\n",
        "  #test.plot_sensors(show_names=True)\n",
        "\n",
        "  # Independent Component Analysis (ICA)\n",
        "  ica = ICA(n_components=20, max_iter='auto', random_state=97) # ICA fitting is not deterministic so we specify a random seed to get identical results each time we run the code\n",
        "  ica.fit(filt_raw)\n",
        "\n",
        "  # Plot ICA results\n",
        "  print(\"ICA results for {}\".format(filename))\n",
        "  ica.plot_components()\n",
        "  ica.plot_sources(filt_raw, show_scrollbars=False)\n"
      ],
      "metadata": {
        "id": "io3a6HIkh8nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plots created by the previous code block were visually inspected. \n",
        "Components to extract from the signal were manually selected and entered to the 'icas.txt' file that will be opened in the next code block."
      ],
      "metadata": {
        "id": "BSExr84dkqcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Opening the ICAs textfile:\n",
        "selected_icas = pd.read_csv('drive/MyDrive/Bachelorthesis/icas.txt', sep=\"; \", header=0, names=[\"Data\", \"ICAs\"])\n",
        "#pd.read_csv automatically converts the ICA lists to strings. To convert back:\n",
        "selected_icas.loc[:,'ICAs'] = selected_icas.loc[:,'ICAs'].apply(lambda x: literal_eval(x))\n",
        "#print(selected_icas)"
      ],
      "metadata": {
        "id": "gUOrbR8JlFA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply ICA\n",
        "\n",
        "for f in os.listdir(\"drive/MyDrive/Bachelorthesis/Concatenated Files\"):\n",
        "  filename = str(f)\n",
        "  subject = filename.strip(\"EPM\")\n",
        "  subject = subject[0:2]\n",
        "  if subject[0] == \"0\":\n",
        "    subject = subject.strip(\"0\")\n",
        "  raw = mne.io.read_raw_fif(\"drive/MyDrive/Bachelorthesis/Concatenated Files/{}\".format(filename), preload=True) #Or use testfile.load_data() for loading\n",
        "  # To print file info use print(testfile.info)\n",
        "  # To print the channels use print(testfile.ch_names)\n",
        "\n",
        "  # Set reference\n",
        "  raw.set_eeg_reference(ref_channels=['Cz'])\n",
        "\n",
        "  # Adjust channel types\n",
        "  if subject < 21: # the data collected for participants from the first round (1-17) were collected with a different system than in the second round\n",
        "    raw.set_channel_types(mapping={'EXG1':'eog', 'EXG2':'eog', 'EXG3':'eog', 'EXG4':'eog', 'EXG5':'eog', 'EXG6':'eog', 'EXG7':'misc', 'EXG8':'misc', 'GSR1':'misc', 'GSR2':'misc', 'Erg1':'misc', 'Erg2':'misc', 'Resp':'misc', 'Plet':'misc', 'Temp':'misc', 'Status':'stim'})\n",
        "    # Rereference to the mastoid links\n",
        "    raw.set_eeg_reference(ref_channels=['EXG1', 'EXG2'])\n",
        "  else: # the data collected for participants from the second round (21-32) were collected with a different system than in the first round\n",
        "    raw.set_channel_types(mapping={'M1':'eog', 'M2':'eog', 'Up':'eog', 'Down':'eog', 'Left':'eog', 'Right':'eog', 'Status':'stim'}) \n",
        "    # Rereference to the mastoid links\n",
        "    raw.set_eeg_reference(ref_channels=['M1', 'M2'])\n",
        "\n",
        "  # Apply signal filtering (while maintaining the raw file)\n",
        "  filt_raw = raw.copy()\n",
        "  filt_raw.notch_filter(freqs=50) #to remove power artefacts from the measuring devices, which are known to be at 50 Hz\n",
        "  filt_raw.filter(l_freq=0.1, h_freq=None)\n",
        "  filt_raw.filter(l_freq=None, h_freq=100)\n",
        "\n",
        "  # Align sensors with their correct position (EEG Sensor Cap)\n",
        "  biosemi_montage = mne.channels.make_standard_montage('biosemi64')\n",
        "  filt_raw.set_montage(biosemi_montage)\n",
        "  #test.plot_sensors(show_names=True)\n",
        "\n",
        "  # Independent Component Analysis (ICA)\n",
        "  ica = ICA(n_components=20, max_iter='auto', random_state=97) # ICA fitting is not deterministic so we specify a random seed to get identical results each time we run the code\n",
        "  ica.fit(filt_raw)\n",
        "\n",
        "  # Plot ICA results\n",
        "  #print(\"ICA results for {}\".format(filename))\n",
        "  #ica.plot_components()\n",
        "  #ica.plot_sources(filt_raw, show_scrollbars=False)\n",
        "\n",
        "  # Pick ICA components\n",
        "  s_filename = filename.strip(\"_raw.fif\")\n",
        "  ica_list = selected_icas.query(\"Data=='{}'\".format(s_filename))[\"ICAs\"].values.tolist()[0]\n",
        "  ica.exclude = ica_list #We specify which ICAs to remove by setting the ica.exclude attribute\n",
        "  reconst_raw = filt_raw.copy() \n",
        "  ica.apply(reconst_raw) #Here we actually apply (in place) the removal of the selected ICAs\n",
        "\n",
        "  # Save filtered data\n",
        "  path = \"drive/MyDrive/Bachelorthesis/ICA Processed Files/{}_ica_raw.fif\".format(s_filename) \n",
        "  reconst_raw.save(path, overwrite=True)\n",
        "\n",
        "  print(\"COMPLETED {}\".format(s_filename))\n"
      ],
      "metadata": {
        "id": "iKeurDk-lQbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define necessary variables for the epoching\n",
        "meta_info = pd.read_csv('drive/MyDrive/Bachelorthesis/meta_info.csv', sep=\";\") #here we can see the accuracy per participant per trial\n",
        "stimulus_info = pd.read_excel('drive/MyDrive/Bachelorthesis/stimuli.xlsx') #here we can see the sequence length per stimulus\n",
        "\n",
        "fcc_event_dict = {'start FCC':101} # The FCC trials are indicated by the 101 markers\n",
        "ecc_event_dict = {'start ECC':102} # The ECC trials are indicated by the 102 markers\n",
        "\n",
        "r1_drop = ['EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'EXG7', 'EXG8', 'GSR1', 'GSR2', 'Erg1', 'Erg2', 'Resp', 'Plet', 'Temp']\n",
        "r2_drop = ['M1', 'M2', 'Up', 'Down', 'Left', 'Right']"
      ],
      "metadata": {
        "id": "ZKMC3qaXlvCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating FCC Epochs\n",
        "\n",
        "LT_FCC_Epochs = None\n",
        "MT_FCC_Epochs = None\n",
        "DT_FCC_Epochs = None\n",
        "\n",
        "for f in os.listdir(\"drive/MyDrive/Bachelorthesis/ICA Processed Files\"):\n",
        "  filename = str(f)\n",
        "  if filename == \"EPM03_MT_ica_raw.fif\" or filename == \"EPM13_MT_ica_raw.fif\" or filename == \"EPM25_LT_ica_raw.fif\": \n",
        "  #3_MT does not work (meta has 37 rows and there are 36 events for the ECC trials), \n",
        "  #13_MT does not work (meta has 36 rows and there are 35 events for both the FCC and ECC trials),\n",
        "  #25_LT does not work (meta has 36 rows while there are only 22 events)\n",
        "    continue\n",
        "  print(\"\\nWorking on {}\".format(filename))\n",
        "  task = filename.strip(\"_ica_raw.fif\")[-2:]\n",
        "  subject = filename.strip(\"{}_ica_raw.fif\".format(task))\n",
        "  subject = subject.strip(\"EPM\")\n",
        "  if subject[0] == \"0\":\n",
        "    subject.strip(\"0\")\n",
        "  print(subject)\n",
        "\n",
        "  # Load file and create epochs\n",
        "  raw = mne.io.read_raw_fif(\"drive/MyDrive/Bachelorthesis/ICA Processed Files/{}\".format(filename), preload=True) \n",
        "  if int(subject) < 21: #to make sure all epochs have the same number of channels\n",
        "    raw.drop_channels(r1_drop)\n",
        "  else:\n",
        "    raw.drop_channels(r2_drop)\n",
        "  events = mne.find_events(raw, stim_channel=\"Status\") \n",
        "  fcc_epochs = mne.Epochs(raw, events, event_id=fcc_event_dict, tmin=-1, tmax=3.6, preload=True) #all fcc trials are 3.6 seconds long (6 items)\n",
        "\n",
        "  # Add metadata\n",
        "  fcc_metadata = {} # To link the subject number and response accuracy to the epochs. Later we turn this into a pd.DataFrame\n",
        "\n",
        "  participantx = meta_info[meta_info[\"Subject\"] == int(subject)]\n",
        "  task_px = participantx[participantx[\"Session\"] == task]\n",
        "  if filename == \"EPM04_MT_ica_raw.fif\":  #4_MT is missing EEG data from block 5 (see log-book)\n",
        "    for x in range(501, 537):\n",
        "      task_px = task_px[task_px[\"BlockTrial\"] != x]\n",
        "  fcc_tpx = task_px[task_px[\"Condition\"] == \"FCC\"]\n",
        "  fcc_responses = list(fcc_tpx[\"Accuracy\"]) \n",
        "  # Add the list of response accuracies to the metadata dictionary\n",
        "  fcc_metadata[\"accuracy\"] = fcc_responses\n",
        "  # Add participantnumber to metadata dictionary\n",
        "  subject_meta = [subject for _ in range(len(fcc_responses))]\n",
        "  fcc_metadata[\"subject\"] = subject_meta\n",
        "  #print(metadata)\n",
        "  fcc_meta_df = pd.DataFrame(fcc_metadata)\n",
        "  fcc_epochs.metadata = fcc_meta_df\n",
        "  #print(fcc_epochs.metadata)\n",
        "\n",
        "  # Concatenate Epochs\n",
        "  if task == \"LT\":\n",
        "    if LT_FCC_Epochs == None:\n",
        "      LT_FCC_Epochs = fcc_epochs\n",
        "    else:\n",
        "      LT_FCC_Epochs = mne.concatenate_epochs([LT_FCC_Epochs, fcc_epochs])\n",
        "  if task == \"MT\":\n",
        "    if MT_FCC_Epochs == None:\n",
        "      MT_FCC_Epochs = fcc_epochs\n",
        "    else:\n",
        "      MT_FCC_Epochs = mne.concatenate_epochs([MT_FCC_Epochs, fcc_epochs])\n",
        "  if task == \"DT\":\n",
        "    if DT_FCC_Epochs == None:\n",
        "      DT_FCC_Epochs = fcc_epochs\n",
        "    else:\n",
        "      DT_FCC_Epochs = mne.concatenate_epochs([DT_FCC_Epochs, fcc_epochs])\n",
        "\n",
        "LT_FCC_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/LT_FCC_Epochs.fif', overwrite=True)\n",
        "MT_FCC_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/MT_FCC_Epochs.fif', overwrite=True)\n",
        "DT_FCC_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/DT_FCC_Epochs.fif', overwrite=True)\n"
      ],
      "metadata": {
        "id": "N927aEXSymju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating ECC Epochs\n",
        "\n",
        "LT_ECC9_Epochs = None\n",
        "LT_ECC10_Epochs = None\n",
        "LT_ECC11_Epochs = None\n",
        "LT_ECC12_Epochs = None\n",
        "\n",
        "MT_ECC9_Epochs = None\n",
        "MT_ECC10_Epochs = None\n",
        "MT_ECC11_Epochs = None\n",
        "MT_ECC12_Epochs = None\n",
        "\n",
        "DT_ECC9_Epochs = None\n",
        "DT_ECC10_Epochs = None\n",
        "DT_ECC11_Epochs = None\n",
        "DT_ECC12_Epochs = None\n",
        "\n",
        "for f in os.listdir(\"drive/MyDrive/Bachelorthesis/ICA Processed Files\"):\n",
        "  filename = str(f)\n",
        "  if filename == \"EPM03_MT_ica_raw.fif\" or filename == \"EPM13_MT_ica_raw.fif\" or filename == \"EPM25_LT_ica_raw.fif\": \n",
        "  #3_MT does not work (meta has 37 rows and there are 36 events for the ECC trials), \n",
        "  #13_MT does not work (meta has 36 rows and there are 35 events for both the FCC and ECC trials),\n",
        "  #25_LT does not work (meta has 36 rows while there are only 22 events)\n",
        "    continue\n",
        "  print(\"\\n Working on {}\".format(filename))\n",
        "  task = filename.strip(\"_ica_raw.fif\")[-2:]\n",
        "  subject = filename.strip(\"{}_ica_raw.fif\".format(task))\n",
        "  subject = subject.strip(\"EPM\")\n",
        "  if subject[0] == \"0\":\n",
        "    subject.strip(\"0\")\n",
        "\n",
        "  # Load file and create epochs\n",
        "  raw = mne.io.read_raw_fif(\"drive/MyDrive/Bachelorthesis/ICA Processed Files/{}\".format(filename), preload=True) \n",
        "  if int(subject) < 21: #to make sure all epochs have the same number of channels\n",
        "    raw.drop_channels(r1_drop)\n",
        "  else:\n",
        "    raw.drop_channels(r2_drop)\n",
        "  events = mne.find_events(raw, stim_channel=\"Status\") \n",
        "  ecc_epochs = mne.Epochs(raw, events, event_id=ecc_event_dict, tmin=-1, tmax=7.2, preload=True) # 7.2 seconds is the longest ECC trial\n",
        "\n",
        "  # Add metadata\n",
        "  ecc_metadata = {} # To link the participant number, sequence length and response accuracy to the epochs. Later we turn this into a pd.DataFrame \n",
        "\n",
        "  participantx = meta_info[meta_info[\"Subject\"] == int(subject)]\n",
        "  task_px = participantx[participantx[\"Session\"] == task]\n",
        "  if filename == \"EPM04_MT_ica_raw.fif\":  #4_MT is missing EEG data from block 5 (see log-book)\n",
        "    for x in range(501, 537):\n",
        "      task_px = task_px[task_px[\"BlockTrial\"] != x]\n",
        "  ecc_tpx = task_px[task_px[\"Condition\"] == \"ECC\"]\n",
        "  ecc_responses = list(ecc_tpx[\"Accuracy\"]) \n",
        "  # Add the list of response accuracies to the metadata dictionary\n",
        "  ecc_metadata[\"accuracy\"] = ecc_responses\n",
        "  # Add the subject number to the metadata dictionary\n",
        "  subject_meta = [subject for _ in range(len(ecc_responses))]\n",
        "  ecc_metadata[\"subject\"] = subject_meta\n",
        "  ecc_stimulus_length = []\n",
        "  for stimulus in ecc_tpx[\"audio\"]:\n",
        "    for soundname in stimulus_info[\"SoundStimNRWords\"]:\n",
        "      if stimulus in soundname:\n",
        "        # Add the length of the stimulus to the list\n",
        "        ecc_stimulus_length.append(list(stimulus_info[stimulus_info[\"SoundStimNRWords\"]==soundname][\"NRWords\"])[0])\n",
        "        break\n",
        "  # Add the list of stimulus lengths to the metadata dictionary        \n",
        "  ecc_metadata[\"stim_length\"] = ecc_stimulus_length\n",
        "  #print(metadata)\n",
        "  ecc_meta_df = pd.DataFrame(ecc_metadata)\n",
        "  ecc_epochs.metadata = ecc_meta_df\n",
        "  #print(ecc_epochs.metadata)\n",
        "\n",
        "  # Crop epochs based on sequence length\n",
        "  ecc9 = ecc_epochs['stim_length == 9'].crop(tmin=-1, tmax=5.4)\n",
        "  ecc10 = ecc_epochs['stim_length == 10'].crop(tmin=-1, tmax=6.0)\n",
        "  ecc11 = ecc_epochs['stim_length == 11'].crop(tmin=-1, tmax=6.6)\n",
        "  ecc12 = ecc_epochs['stim_length == 12']\n",
        "\n",
        "  # Concatenate Epochs\n",
        "  if task == \"LT\":\n",
        "    if LT_ECC9_Epochs == None:\n",
        "      LT_ECC9_Epochs = ecc9\n",
        "      LT_ECC10_Epochs = ecc10\n",
        "      LT_ECC11_Epochs = ecc11\n",
        "      LT_ECC12_Epochs = ecc12\n",
        "    else:\n",
        "      LT_ECC9_Epochs = mne.concatenate_epochs([LT_ECC9_Epochs, ecc9])\n",
        "      LT_ECC10_Epochs = mne.concatenate_epochs([LT_ECC10_Epochs, ecc10])\n",
        "      LT_ECC11_Epochs = mne.concatenate_epochs([LT_ECC11_Epochs, ecc11])\n",
        "      LT_ECC12_Epochs = mne.concatenate_epochs([LT_ECC12_Epochs, ecc12])\n",
        "  if task == \"MT\":\n",
        "    if MT_ECC9_Epochs == None:\n",
        "      MT_ECC9_Epochs = ecc9\n",
        "      MT_ECC10_Epochs = ecc10\n",
        "      MT_ECC11_Epochs = ecc11\n",
        "      MT_ECC12_Epochs = ecc12\n",
        "    else:\n",
        "      MT_ECC9_Epochs = mne.concatenate_epochs([MT_ECC9_Epochs, ecc9])\n",
        "      MT_ECC10_Epochs = mne.concatenate_epochs([MT_ECC10_Epochs, ecc10])\n",
        "      MT_ECC11_Epochs = mne.concatenate_epochs([MT_ECC11_Epochs, ecc11])\n",
        "      MT_ECC12_Epochs = mne.concatenate_epochs([MT_ECC12_Epochs, ecc12])\n",
        "  if task == \"DT\":\n",
        "    if DT_ECC9_Epochs == None:\n",
        "      DT_ECC9_Epochs = ecc9\n",
        "      DT_ECC10_Epochs = ecc10\n",
        "      DT_ECC11_Epochs = ecc11\n",
        "      DT_ECC12_Epochs = ecc12\n",
        "    else:\n",
        "      DT_ECC9_Epochs = mne.concatenate_epochs([DT_ECC9_Epochs, ecc9])\n",
        "      DT_ECC10_Epochs = mne.concatenate_epochs([DT_ECC10_Epochs, ecc10])\n",
        "      DT_ECC11_Epochs = mne.concatenate_epochs([DT_ECC11_Epochs, ecc11])\n",
        "      DT_ECC12_Epochs = mne.concatenate_epochs([DT_ECC12_Epochs, ecc12])\n",
        "\n",
        "LT_ECC9_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/LT_ECC9_Epochs.fif', overwrite=True)\n",
        "LT_ECC10_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/LT_ECC10_Epochs.fif', overwrite=True)\n",
        "LT_ECC11_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/LT_ECC11_Epochs.fif', overwrite=True)\n",
        "LT_ECC12_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/LT_ECC12_Epochs.fif', overwrite=True)\n",
        "\n",
        "MT_ECC9_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/MT_ECC9_Epochs.fif', overwrite=True)\n",
        "MT_ECC10_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/MT_ECC10_Epochs.fif', overwrite=True)\n",
        "MT_ECC11_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/MT_ECC11_Epochs.fif', overwrite=True)\n",
        "MT_ECC12_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/MT_ECC12_Epochs.fif', overwrite=True)\n",
        "\n",
        "DT_ECC9_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/DT_ECC9_Epochs.fif', overwrite=True)\n",
        "DT_ECC10_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/DT_ECC10_Epochs.fif', overwrite=True)\n",
        "DT_ECC11_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/DT_ECC11_Epochs.fif', overwrite=True)\n",
        "DT_ECC12_Epochs.save('drive/MyDrive/Bachelorthesis/Epochs/DT_ECC12_Epochs.fif', overwrite=True)"
      ],
      "metadata": {
        "id": "hjx8xB8MyyBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results will be formatted as a table (.csv file) with columns:\n",
        "  # - subject  \n",
        "  # - task (LT/MT/DT)\n",
        "  # - condition (ECC/FCC)\n",
        "  # - electrode (64 in total)\n",
        "  # - alpha power (average over the band frequencies and over corresponding trials)\n",
        "  # - response accuracy (average over corresponding trials)\n",
        "  # - sequence length (6 for FCC, 9, 10, 11 or 12 for ECC)"
      ],
      "metadata": {
        "id": "L4VyK-Kzy5jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = { # to store the results; for now include the 'epoch' and later average the alpha_power over corresponding epochs\n",
        "    \"subject\":[],\n",
        "    \"task\":[],\n",
        "    \"condition\":[],\n",
        "    \"epoch\":[],\n",
        "    \"electrode\":[],\n",
        "    \"alpha_power\":[],\n",
        "    \"response_acc\":[],\n",
        "    \"stimulus_len\":[]\n",
        "} \n",
        "\n",
        "for f in os.listdir(\"drive/MyDrive/Bachelorthesis/Epochs\"):\n",
        "  filename = str(f)\n",
        "  print(\"\\nWorking on {}\".format(filename))\n",
        "  task = filename[0:2]\n",
        "  if \"ECC\" in filename:\n",
        "    condition = \"ECC\"\n",
        "    if \"9\" in filename:\n",
        "      stim_len = 9\n",
        "    elif \"10\" in filename:\n",
        "      stim_len = 10\n",
        "    elif \"11\" in filename:\n",
        "      stim_len = 11\n",
        "    elif \"12\" in filename:\n",
        "      stim_len = 12\n",
        "  else:\n",
        "    condition = \"FCC\"\n",
        "    stim_len = 6\n",
        "  # Load epochs\n",
        "  epoch_obj = mne.read_epochs(\"drive/MyDrive/Bachelorthesis/Epochs/{}\".format(filename), preload=True)\n",
        "\n",
        "  # Compute TFR power rates\n",
        "  freqs = [8, 9, 10, 11, 12]\n",
        "  n_cycles = [4, 4.5, 5, 5.5, 6]\n",
        "  power = mne.time_frequency.tfr_morlet(epoch_obj, average=False, return_itc=False, n_cycles=n_cycles, freqs=freqs) # average=False so that TFR is computed for each epoch seperately\n",
        "  #this function creates a EpochsTFR container with among others the attributes:\n",
        "  # - data (4D-array with power values; dims are n_epochs, n_channels, n_freqs and time)\n",
        "  # - ch_names \n",
        "  # - metadata\n",
        "\n",
        "  # Loop over the results and update results dictionary\n",
        "  for epoch_nr in range(0, power.data.shape[0]):\n",
        "    epoch = epoch_nr+1\n",
        "    response = list(power.metadata[\"accuracy\"])[epoch_nr]\n",
        "    subject = list(power.metadata[\"subject\"])[epoch_nr]\n",
        "    for chan_nr in range(0, power.data.shape[1]):\n",
        "      #subject\n",
        "      results[\"subject\"].append(subject)\n",
        "      #task\n",
        "      results[\"task\"].append(task)\n",
        "      #condition\n",
        "      results[\"condition\"].append(condition)\n",
        "      #epoch\n",
        "      results[\"epoch\"].append(epoch)\n",
        "      #channel\n",
        "      results[\"electrode\"].append(power.ch_names[chan_nr])\n",
        "      #alpha_power\n",
        "      results[\"alpha_power\"].append(np.average(power.data[epoch_nr, chan_nr]))\n",
        "      #response_acc\n",
        "      results[\"response_acc\"].append(response)\n",
        "      #stimulus_len\n",
        "      results[\"stimulus_len\"].append(stim_len)\n",
        "\n",
        "  # To compute average power over all epochs:\n",
        "  #power.average()"
      ],
      "metadata": {
        "id": "3cpqHmV8zH0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average results over corresponding epochs\n",
        "\n",
        "final_results = {\n",
        "    \"subject\":[],\n",
        "    \"task\":[],\n",
        "    \"condition\":[],\n",
        "    \"electrode\":[],\n",
        "    \"alpha_power\":[], #averaged over corresponding trials\n",
        "    \"response_acc\":[], #averaged over corresponding trials\n",
        "    \"stimulus_len\":[]\n",
        "}\n",
        "\n",
        "#subjects = list(set(results[\"subject\"])).sort()\n",
        "tasks = [\"MT\", \"LT\", \"DT\"]\n",
        "conditions = [\"ECC\", \"FCC\"]\n",
        "subjects = list(set(results[\"subject\"]))\n",
        "subjects.sort()\n",
        "electrodes = list(set(results[\"electrode\"]))\n",
        "electrodes.sort()\n",
        "lengths = [9, 10, 11, 12]\n",
        "\n",
        "# Subset the results dataframe and compute average power and response values.\n",
        "# Add results to the new 'final_results' dictionary\n",
        "for s in subjects:\n",
        "  print(\"Working on subject:\", s)\n",
        "  for t in tasks:\n",
        "    for c in conditions:\n",
        "      for e in electrodes:\n",
        "        if c == \"ECC\":\n",
        "          for l in lengths:\n",
        "            subdf = results[results[\"subject\"] == s][results[\"task\"] == t][results[\"condition\"] == c][results[\"electrode\"] == e][results[\"stimulus_len\"] == l]\n",
        "            av_pow = subdf[\"alpha_power\"].mean()\n",
        "            av_res = subdf[\"response_acc\"].mean()\n",
        "            #subject\n",
        "            final_results[\"subject\"].append(s)\n",
        "            #task\n",
        "            final_results[\"task\"].append(t)\n",
        "            #condition\n",
        "            final_results[\"condition\"].append(c)\n",
        "            #channel\n",
        "            final_results[\"electrode\"].append(e)\n",
        "            #alpha_power\n",
        "            final_results[\"alpha_power\"].append(av_pow)\n",
        "            #response_acc\n",
        "            final_results[\"response_acc\"].append(av_res)\n",
        "            #stimulus_len\n",
        "            final_results[\"stimulus_len\"].append(l)\n",
        "        else:\n",
        "          subdf = results[results[\"subject\"] == s][results[\"task\"] == t][results[\"condition\"] == c][results[\"electrode\"] == e]\n",
        "          av_pow = subdf[\"alpha_power\"].mean()\n",
        "          av_res = subdf[\"response_acc\"].mean()\n",
        "          #subject\n",
        "          final_results[\"subject\"].append(s)\n",
        "          #task\n",
        "          final_results[\"task\"].append(t)\n",
        "          #condition\n",
        "          final_results[\"condition\"].append(c)\n",
        "          #channel\n",
        "          final_results[\"electrode\"].append(e)\n",
        "          #alpha_power\n",
        "          final_results[\"alpha_power\"].append(av_pow)\n",
        "          #response_acc\n",
        "          final_results[\"response_acc\"].append(av_res)\n",
        "          #stimulus_len\n",
        "          final_results[\"stimulus_len\"].append(6)\n"
      ],
      "metadata": {
        "id": "sPnnR-ojzShg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final file should look like:\n",
        "- Subjects (25 participants)\n",
        "- Task (3 levels: MT, LT, DT)\n",
        "- Condition (2 levels: ECC, FCC)\n",
        "- Hemisphere (2: left, right)\n",
        "- Region (3 levels: frontal, central, posterior)\n",
        "- Power \n",
        "- Response accuracy\n",
        "- Stimulus length"
      ],
      "metadata": {
        "id": "C7P2COzC0WJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define brain regions\n",
        "left = [\"Fp1\", \"AF7\", \"AF3\", \"F7\", \"F5\", \"F3\", \"F1\", \"FT7\", \"FC5\", \"FC3\", \"FC1\", \"T7\", \"C5\", \"C3\", \"C1\", \"TP7\", \"CP5\", \"CP3\", \"CP1\", \"P9\", \"P7\", \"P5\", \"P3\", \"P1\", \"PO7\", \"PO3\", \"O1\"]\n",
        "right = [\"FP2\", \"AF4\", \"AF8\", \"F2\", \"F4\", \"F6\", \"F8\", \"FC2\", \"FC4\", \"FC6\", \"FT8\", \"C2\", \"C4\", \"C6\", \"T8\", \"CP2\", \"CP4\", \"CP6\", \"TP8\", \"P2\", \"P4\", \"P6\", \"P8\", \"P10\", \"PO4\", \"PO8\", \"O2\"]\n",
        "frontal = [\"Fp1\", \"AF7\", \"AF3\", \"F7\", \"F5\", \"F3\", \"F1\", \"FT7\", \"FC5\", \"FC3\", \"FC1\", \"FP2\", \"AF4\", \"AF8\", \"F2\", \"F4\", \"F6\", \"F8\", \"FC2\", \"FC4\", \"FC6\", \"FT8\", \"Fpz\", \"AFz\", \"Fz\", \"FCz\"]\n",
        "central = [\"T7\", \"C5\", \"C3\", \"C1\", \"TP7\", \"CP5\", \"CP3\", \"CP1\", \"C2\", \"C4\", \"C6\", \"T8\", \"CP2\", \"CP4\", \"CP6\", \"TP8\", \"Cz\", \"CPz\"]\n",
        "posterior = [\"P9\", \"P7\", \"P5\", \"P3\", \"P1\", \"PO7\", \"PO3\", \"O1\", \"P2\", \"P4\", \"P6\", \"P8\", \"P10\", \"PO4\", \"PO8\", \"O2\", \"Pz\", \"POz\", \"Oz\", \"Iz\"]"
      ],
      "metadata": {
        "id": "ZVNtqtNRzNjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reformat results by averaging over brain regions\n",
        "results = final_results\n",
        "\n",
        "final_results = { # to store the results\n",
        "#per subject/task/condition/stim_len: group the electrodes into regions and hemispheres and compute the average alpha power\n",
        "    \"subject\":[],\n",
        "    \"task\":[],\n",
        "    \"condition\":[],\n",
        "    \"hemisphere\":[],\n",
        "    \"region\":[],\n",
        "    \"alpha_power\":[],\n",
        "    \"response_acc\":[],\n",
        "    \"stimulus_len\":[]\n",
        "} \n",
        "\n",
        "subjects = list(set(results[\"subject\"]))\n",
        "subjects.sort()\n",
        "tasks = [\"MT\", \"LT\", \"DT\"]\n",
        "conditions = [\"ECC\", \"FCC\"]\n",
        "hemispheres = [left, right]\n",
        "regions = [frontal, central, posterior]\n",
        "electrodes = list(set(results[\"electrode\"]))\n",
        "electrodes.sort()\n",
        "lengths = [9, 10, 11, 12]\n",
        "\n",
        "# Subset the final_results dataframe and compute average power and response values.\n",
        "# Add results to the new 'final' dictionary\n",
        "for s in subjects:\n",
        "  print(\"Working on subject:\", s)\n",
        "  for t in tasks:\n",
        "    for c in conditions: \n",
        "      for h in hemispheres:\n",
        "        for r in regions:\n",
        "          if c == \"ECC\":\n",
        "            for l in lengths:\n",
        "              subdf = results[results[\"subject\"] == s][results[\"task\"] == t][results[\"condition\"] == c][results[\"stimulus_len\"] == l]\n",
        "              subdf = subdf[subdf[\"electrode\"].isin(h)][subdf[\"electrode\"].isin(r)]\n",
        "              av_pow = subdf[\"alpha_power\"].mean()\n",
        "              av_res = subdf[\"response_acc\"].mean()\n",
        "              #subject\n",
        "              final_results[\"subject\"].append(s)\n",
        "              #task\n",
        "              final_results[\"task\"].append(t)\n",
        "              #condition\n",
        "              final_results[\"condition\"].append(c)\n",
        "              #hemisphere\n",
        "              if h == left:\n",
        "                final_results[\"hemisphere\"].append(\"left\")\n",
        "              else:\n",
        "                final_results[\"hemisphere\"].append(\"right\")\n",
        "              #region\n",
        "              if r == frontal:\n",
        "                final_results[\"region\"].append(\"frontal\")\n",
        "              elif r == central:\n",
        "                final_results[\"region\"].append(\"central\")\n",
        "              else:\n",
        "                final_results[\"region\"].append(\"posterior\")\n",
        "              #alpha_power\n",
        "              final_results[\"alpha_power\"].append(av_pow)\n",
        "              #response_acc\n",
        "              final_results[\"response_acc\"].append(av_res)\n",
        "              #stimulus_len\n",
        "              final_results[\"stimulus_len\"].append(l)\n",
        "          else:\n",
        "            subdf = results[results[\"subject\"] == s][results[\"task\"] == t][results[\"condition\"] == c]\n",
        "            subdf = subdf[subdf[\"electrode\"].isin(h)][subdf[\"electrode\"].isin(r)]\n",
        "            av_pow = subdf[\"alpha_power\"].mean()\n",
        "            av_res = subdf[\"response_acc\"].mean()\n",
        "            #subject\n",
        "            final_results[\"subject\"].append(s)\n",
        "            #task\n",
        "            final_results[\"task\"].append(t)\n",
        "            #condition\n",
        "            final_results[\"condition\"].append(c)\n",
        "            #hemisphere\n",
        "            if h == left:\n",
        "              final_results[\"hemisphere\"].append(\"left\")\n",
        "            else:\n",
        "              final_results[\"hemisphere\"].append(\"right\")\n",
        "            #region\n",
        "            if r == frontal:\n",
        "              final_results[\"region\"].append(\"frontal\")\n",
        "            elif r == central:\n",
        "              final_results[\"region\"].append(\"central\")\n",
        "            else:\n",
        "              final_results[\"region\"].append(\"posterior\")              \n",
        "            #alpha_power\n",
        "            final_results[\"alpha_power\"].append(av_pow)\n",
        "            #response_acc\n",
        "            final_results[\"response_acc\"].append(av_res)\n",
        "            #stimulus_len\n",
        "            final_results[\"stimulus_len\"].append(6)"
      ],
      "metadata": {
        "id": "rvog0xmo0kw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict(final_results)\n",
        "#print(df)\n",
        "# Export final results\n",
        "df.to_csv(\"drive/MyDrive/Bachelorthesis/results by region.csv\")\n",
        "df.to_excel(\"drive/MyDrive/Bachelorthesis/results by region.xlsx\")"
      ],
      "metadata": {
        "id": "Mk14PD221Drm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}